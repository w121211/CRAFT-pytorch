{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import craft_utils\n",
    "import imgproc\n",
    "import file_utils\n",
    "import json\n",
    "import zipfile\n",
    "\n",
    "from craft import CRAFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CRAFT()  # initialize\n",
    "state_dict = torch.load(\"craft_mlt_25k.pth\", map_location=\"cpu\")\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    name = k.replace(\"module.\", \"\")  # remove 'module.' of dataparallel\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "net.load_state_dict(new_state_dict)\n",
    "net.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imgproc.loadImage(\"data/0e2f315f1f068638932de997005ff9a6.jpg\")\n",
    "img_resized, target_ratio, size_heatmap = imgproc.resize_aspect_ratio(\n",
    "        image,\n",
    "        1280,\n",
    "        interpolation=cv2.INTER_LINEAR,\n",
    "        mag_ratio=1.5,\n",
    "    )\n",
    "ratio_h = ratio_w = 1 / target_ratio\n",
    "\n",
    "# preprocessing\n",
    "x = imgproc.normalizeMeanVariance(img_resized)\n",
    "x = torch.from_numpy(x).permute(2, 0, 1)  # [h, w, c] to [c, h, w]\n",
    "x = Variable(x.unsqueeze(0))  # [c, h, w] to [b, c, h, w]\n",
    "\n",
    "# forward pass\n",
    "y, _ = net(x)\n",
    "\n",
    "# make score and link map\n",
    "# score_text = y[0, :, :, 0].cpu().data.numpy()\n",
    "# score_link = y[0, :, :, 1].cpu().data.numpy()\n",
    "\n",
    "# render results (optional)\n",
    "# render_img = score_text.copy()\n",
    "# render_img = np.hstack((render_img, score_link))\n",
    "# ret_score_text = imgproc.cvt2HeatmapImg(render_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([544, 608, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.max(render_img*255)\n",
    "# render_img.shape\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "y[0, :, :, 0].unsqueeze(2).shape\n",
    "\n",
    "# render_img = score_text.copy()\n",
    "# render_img = np.expand_dims(render_img, 0)\n",
    "\n",
    "# render_img = torch.Tensor(render_img)\n",
    "# render_img = torch.clamp(render_img, 0, 1)\n",
    "# render_img = render_img * (render_img > 0.01).float()\n",
    "# render_img\n",
    "# render_img.shape\n",
    "\n",
    "# transform = transforms.ToPILImage()\n",
    "# transform(render_img)\n",
    "\n",
    "# ret_score_text = cv2.cvtColor(ret_score_text,cv2.COLOR_BGR2RGB)\n",
    "# pil_im = Image.fromarray(ret_score_text)\n",
    "# pil_im\n",
    "# Image.fromarray(render_img * 255, mode='L')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
